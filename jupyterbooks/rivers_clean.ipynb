{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely.geometry\n",
    "import shapely.ops\n",
    "import pandas as pd\n",
    "import folium\n",
    "import earthpy\n",
    "from ipyleaflet import Map, GeoData, basemaps, LayersControl\n",
    "import json\n",
    "from ipywidgets import HTML\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import time\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buffering parks and clipping rivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bazaruto Archipelago National Park\n",
      "Partial Reserve Namibe\n",
      "Kundelungu\n",
      "Upemba\n",
      "Eastern CAR Wilderness - no settlements no agriculture - 102'000 km2\n",
      "Zone Tampon Ngaoua-Oues\n",
      "Zone Tampon Kobou Nord\n",
      "40 Chinko\n",
      "Zone Tampon Ndji\n",
      "41 Vovodo Chinko\n",
      "Mkululmadzi Concession Area\n",
      "Kidepo Valley\n",
      "Mago\n",
      "Chebera Churchura\n",
      "Omo\n",
      "Zone Tampon Mbari-Ngoumindo\n",
      "High Intensity Tourism Zone - 2wd\n",
      "Gura Ferda\n",
      "Ilha dos Tigres\n",
      "Zone Girafes\n",
      "Tamou Reserve totale\n",
      "ZOC Zone tampon\n",
      "Pendjari Parc National\n",
      "Konkombri ZC\n",
      "Porga ZC\n",
      "Ndesha\n",
      "Kasonso Busanga\n",
      "Lunga Luswishi\n",
      "Mumbwa\n",
      "Gambella\n",
      "Omo New\n",
      "Tama\n",
      "Badingilo\n",
      "Boma National Park\n",
      "Badingilo Extension\n",
      "Zone Tampon Kobou-Est-Yalinga\n",
      "Boma Extension\n",
      "Boma Extension\n",
      "Loelle\n",
      "Proposed Corridor\n",
      "Kahuzi-Biega National Park\n",
      "National Park Iona\n",
      "Melfi Hunting Area\n",
      "Chinko (old)\n",
      "Konkombouri ZC\n",
      "Singou ZC\n",
      "Pagou ZC\n",
      "Ouamou ZC\n",
      "Koakrana ZC\n",
      "Arly Parc National\n",
      "Kourtiagou ZC\n",
      "W / Burkina Parc National\n",
      "T.Djerma ZC\n",
      "W / Niger Parc National\n",
      "Zone Tampon Bananzi\n",
      "Upper west zambezi GMA (North)\n",
      "Upper west zambezi GMA (South)\n",
      "Upper west zambezi GMA (North Centre)\n",
      "Pama Centre Nord ZC\n",
      "Pama Centre Sud ZC\n",
      "Pama Nord ZC\n",
      "Pama Sud ZC\n",
      "Dosso Reserve partielle\n",
      "Zemongo Faunal Reserve Area 9'724km2 L 560km\n",
      "Batia ZC\n",
      "Sichifulo\n",
      "Namwala\n",
      "Greater Chinko PPP with other protected areas\n",
      "Mulobezi\n",
      "Mufunta\n",
      "Bilili\n",
      "Greater Chinko PPP with alain lefol\n",
      "Yata Ngaya 4550 km2\n",
      "André Felix NP 1780 km2\n",
      "Zone Tampon Mbari\n",
      "AC Core Zone 2025\n",
      "48 Bas Chinko\n",
      "36 Trois Rivières\n",
      "39 Mbari\n",
      "Low Intensity Tourism Zone\n",
      "Greater Chinko PPP\n",
      "Resource Use Zone\n",
      "High Intensity Tourism Zone - 4wd\n",
      "Ntokou-Pikounda National Park\n",
      "Zone Girafes\n",
      "Upper west zambezi GMA\n",
      "Pendjari\n",
      "Atakora\n",
      "Zone cynégétique de Atakora\n",
      "Parc National de la Pendjari\n",
      "Bahr Salamat Réserve de Faune\n",
      "Mangochi Forest Reserve\n",
      "Akagera National Park\n",
      "Bangweulu Wetlands\n",
      "Liuwa Plain National Park\n",
      "Ennedi Natural and Cultural Reserve\n",
      "Gangala na Bodio Hunting Domain\n",
      "Mondo Missa Hunting Domain\n",
      "Garamba National Park\n",
      "Liwonde National Park\n",
      "Azande Hunting Domain\n",
      "Majete Wildlife Reserve\n",
      "Matusadona National Park\n",
      "Nkhotakota Wildlife Reserve\n",
      "Odzala-Kokoua National Park\n",
      "Pendjari\n",
      "Luengue-Luiana\n",
      "Mavinga\n",
      "Zakouma National Park\n",
      "W / Bénin Parc National\n",
      "Séri NA\n",
      "Nyungwe\n",
      "Kafue\n",
      "Djona ZC\n",
      "Mekrou ZC\n",
      "Lavushi Manda\n",
      "Lossie Gorilla Sanctuary\n",
      "Réserve de faune de Siniaka-Minia\n",
      "Chinko boundary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maryn/mygit/geospatial/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3364: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "Exception ignored in: <function BaseGeometry.__del__ at 0x7f4de5402dc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maryn/mygit/geospatial/venv/lib/python3.8/site-packages/shapely/geometry/base.py\", line 209, in __del__\n",
      "    self._empty(val=None)\n",
      "  File \"/home/maryn/mygit/geospatial/venv/lib/python3.8/site-packages/shapely/geometry/base.py\", line 191, in _empty\n",
      "    def _empty(self, val=EMPTY):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_5488/1826548885.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     81\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mindex1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mriver1\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mbuffer_rivers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miterrows\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 83\u001B[0;31m     \u001B[0;32mif\u001B[0m \u001B[0mriver1\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'NOID'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpark_rivers\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'NOID'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     84\u001B[0m         \u001B[0mbuffer_rivers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mat\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mindex1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'inpark_par'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/mygit/geospatial/venv/lib/python3.8/site-packages/geopandas/geodataframe.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   1325\u001B[0m         \u001B[0mGeoDataFrame\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1326\u001B[0m         \"\"\"\n\u001B[0;32m-> 1327\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getitem__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1328\u001B[0m         \u001B[0mgeo_col\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_geometry_column_name\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1329\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSeries\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mGeometryDtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/mygit/geospatial/venv/lib/python3.8/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3422\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mis_hashable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3423\u001B[0m             \u001B[0;31m# shortcut if the key is in columns\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3424\u001B[0;31m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_unique\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mkey\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3425\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mMultiIndex\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3426\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/mygit/geospatial/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36m__contains__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4572\u001B[0m         \u001B[0mhash\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4573\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 4574\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mkey\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   4575\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mOverflowError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4576\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "parks = gpd.read_file(\"../../data/rivers/Polygon_layer.shp\").to_crs(epsg=4269)\n",
    "\n",
    "\n",
    "for index, park in parks.iterrows():\n",
    "    print(park.loc['name'])\n",
    "\n",
    "\n",
    "park_name = 'Eastern CAR Wilderness - no settlements no agriculture - 102\\'000 km2'\n",
    "\n",
    "\n",
    "# Buffer\n",
    "park_buffer = parks.loc[parks['name'] == park_name].to_crs('+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs ')\n",
    "\n",
    "park_buffer['geometry'] = park_buffer['geometry'].geometry.buffer(500000)\n",
    "park_buffer = park_buffer.to_crs(epsg=4269)\n",
    "\n",
    "# Park\n",
    "park = parks.loc[parks['name'] == park_name].to_crs('+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs ')\n",
    "park['geometry'] = park['geometry'].geometry.buffer(500)\n",
    "\n",
    "park = park.to_crs(epsg=4269)\n",
    "\n",
    "# Rivers\n",
    "try:\n",
    "    rwa_rivers\n",
    "except NameError:\n",
    "    rwa_rivers = gpd.read_file(\"../../data/rivers/clipped_rivers.shp\").to_crs(epsg=4269)\n",
    "\n",
    "# Buffer rivers\n",
    "buffer_border = gpd.GeoDataFrame(geometry=park_buffer.boundary)\n",
    "buffer_rivers = gpd.sjoin(rwa_rivers, park_buffer, how='inner', predicate='within')\n",
    "\n",
    "# Park rivers\n",
    "park_rivers = gpd.sjoin(rwa_rivers, park, how='inner', predicate='within')\n",
    "\n",
    "park_rivers = park_rivers.reset_index(drop=True)\n",
    "\n",
    "# Set property if in park\n",
    "buffer_rivers['inpark_par'] = 0\n",
    "\n",
    "for index1, river1 in buffer_rivers.iterrows():\n",
    "    if river1['NOID'] in park_rivers['NOID'].values:\n",
    "        buffer_rivers.at[index1, 'inpark_par'] = 1\n",
    "        \n",
    "buffer_rivers = buffer_rivers.rename(columns={'index_left': 'i_l'})\n",
    "buffer_rivers = buffer_rivers.rename(columns={'index_right': 'i_r'})\n",
    "buffer_rivers = buffer_rivers.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Rivers entering the park from outside\n",
    "buffer_rivers['o_outside_dis']=0.0\n",
    "buffer_rivers['o_inflow_par']=0\n",
    "buffer_rivers['o_through_par']=0\n",
    "buffer_rivers['o_park_dis']=0.0 \n",
    "\n",
    "# Rivers starting in park\n",
    "buffer_rivers['i_start_dis']=0.0\n",
    "buffer_rivers['i_park_dis']=0.0 \n",
    "buffer_rivers['i_park_fra']=0.0 \n",
    "\n",
    "# All rivers\n",
    "buffer_rivers['park_dis']=0.0\n",
    "buffer_rivers['intersect_par'] = 0\n",
    "buffer_rivers['park_fra']=0.0 \n",
    "\n",
    "# Rivers on boundary of park\n",
    "park_rivers['intersect_par'] = 0\n",
    "park_rivers['o_outside_dis']=0.0\n",
    "buffer_rivers['o_park_fra']=0.0 \n",
    "\n",
    "\n",
    "park_border = gpd.GeoDataFrame(geometry=park.boundary)\n",
    "all_inters = gpd.sjoin(buffer_rivers, park_border, op='intersects')\n",
    "\n",
    "\n",
    "\n",
    "for index1, river1 in buffer_rivers.iterrows():\n",
    "    if river1['NOID'] in all_inters['NOID'].values:\n",
    "        buffer_rivers.at[index1, 'intersect_par'] = 1\n",
    "        buffer_rivers.at[index1, 'inpark_par'] = 1\n",
    "\n",
    "for index1, river1 in buffer_rivers.iterrows():\n",
    "    if river1['NOID'] in park_rivers['NOID'].values:\n",
    "        buffer_rivers.at[index1, 'inpark_par'] = 1\n",
    "        \n",
    "\n",
    "for index1, river1 in all_inters.iterrows():\n",
    "    if river1['NOID'] in park_rivers['NOID'].values:\n",
    "        park_rivers.at[index1, 'intersect_par'] = 1  \n",
    "        \n",
    "\n",
    "all_inters = all_inters.reset_index(drop=True)        \n",
    "inters = gpd.GeoDataFrame()\n",
    "for index1, r1 in all_inters.iterrows():\n",
    "    already_intersected = 0\n",
    "    for index2, r2 in all_inters.iterrows():\n",
    "        if r1['NOID'] == r2['NDOID']:\n",
    "            already_intersected = 1\n",
    "    if already_intersected != 1:\n",
    "        inters = inters.append(all_inters.iloc[index1])\n",
    "            \n",
    "# Make df of all rivers inside and intersecting park\n",
    "in_park = park_rivers.append(inters)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_aspect('equal')\n",
    "buffer_rivers.plot(ax=ax, color='grey')\n",
    "park_border.plot(ax=ax, color='red')\n",
    "in_park.plot(ax=ax, color='orange')\n",
    "\n",
    "# inters.plot(ax=ax, color='blue')\n",
    "plt.show();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find upstream river outside park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_inters = gpd.GeoDataFrame()\n",
    "inters = inters.reset_index(drop=True)\n",
    "\n",
    "# Loop through all rivers intersecting with park border\n",
    "for index1, r1 in inters.iterrows():\n",
    "    # All rivers starting\n",
    "    if r1['NUOID'] is None:\n",
    "        pass\n",
    "    # All rivers not starting\n",
    "    else:\n",
    "        for index2, r2 in buffer_rivers.loc[buffer_rivers['NDOID']==r1['NOID']].iterrows():\n",
    "            # If river (r2) flows into river on border (r1)\n",
    "            if r1['NOID'] == r2['NDOID']:\n",
    "                # to make sure upstream river (r2) is outside the park\n",
    "                if r2['inpark_par'] != 1:\n",
    "                    # then upstream river (r2) is flowing into the park\n",
    "                    inters.at[index1, 'o_inflow_par'] = 1\n",
    "                    in_inters = in_inters.append(inters.iloc[index1])\n",
    "\n",
    "print(inters.loc[inters['o_inflow_par']==1,'NOID'])                   \n",
    "\n",
    "# Set the o_inflow_par of buffer_rivers also to 1\n",
    "buffer_rivers.loc[buffer_rivers['NOID'].isin(inters.loc[inters['o_inflow_par']==1,'NOID']), 'o_inflow_par'] = 1\n",
    "\n",
    "# If there are rivers flowing into the park\n",
    "if in_inters.shape[0] > 0:                \n",
    "\n",
    "    # drop all duplicate in-flowing rivers\n",
    "    in_inters = in_inters.drop_duplicates()\n",
    "    print('Number of inflowing rivers: ' + str(len(in_inters)))\n",
    "\n",
    "    # set property on buffer_rivers to know that river is entering the park from outside\n",
    "# may be REDUNDANT\n",
    "    for index1, river1 in buffer_rivers.iterrows():\n",
    "        if river1['NOID'] in in_inters['NOID'].values:\n",
    "            buffer_rivers.at[index1, 'o_inflow_par'] = 1  \n",
    "\n",
    "    # plot to show in-flowing rivers\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_aspect('equal')\n",
    "    park_border.plot(ax=ax, color='grey')\n",
    "    park_rivers.plot(ax=ax, color='black')\n",
    "    inters.plot(ax=ax, color='blue')\n",
    "    in_inters.plot(ax=ax, color='red')\n",
    "    plt.show();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating outside flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_inters.shape[0] > 0:                \n",
    "\n",
    "    for index1, r1 in in_inters.iterrows(): \n",
    "        print(\"\\n\")\n",
    "        print(r1['NOID'])\n",
    "        print('start_flow: ' + str(r1['DIS_AV_CMS'] ))\n",
    "\n",
    "\n",
    "        run = 0\n",
    "        # If the river has reached the park boundary and is now flowing out\n",
    "        out_flow = 0\n",
    "        new_inters = gpd.GeoDataFrame()\n",
    "\n",
    "        # While the river is still inside the park\n",
    "        while out_flow == 0:\n",
    "            run += 1\n",
    "            print('run' + str(run))\n",
    "            # If in-flowing rivers on park boundary\n",
    "            if run == 1:\n",
    "                # For the next downstream rivers\n",
    "                for index2, r2 in buffer_rivers.loc[buffer_rivers['NOID']==r1['NDOID']].iterrows():\n",
    "                    # If inflowing river (r1) is flowing into downstream river (r2)\n",
    "                    if r1['NDOID'] == r2['NOID']:\n",
    "\n",
    "                        # Set the downstream river (r2)'s outside flow to the inflowing river (r1)'s flow\n",
    "                        buffer_rivers.at[index2, 'o_outside_dis'] = r2['o_outside_dis']  + r1['DIS_AV_CMS']\n",
    "                        \n",
    "                        print('o_outside_dis: ' + str(buffer_rivers.at[index2, 'o_outside_dis']))\n",
    "                        \n",
    "                        # Add r2 to become the next round's upstream river\n",
    "                        new_inters = new_inters.append(buffer_rivers.iloc[index2])\n",
    "                        \n",
    "                        # Check if r2 is already crossing the park boundary (leaving the park)\n",
    "                        if r2['inpark_par'] == 0:\n",
    "                            out_flow = 1\n",
    "                        else:\n",
    "                            buffer_rivers.at[index2, 'o_through_par'] = 1\n",
    "                            \n",
    "\n",
    "            # If not the in-flowing river, but a next-in-line downstream river\n",
    "\n",
    "            else:\n",
    "                for index3, r3 in new_inters.iterrows():\n",
    "                    new_inters = gpd.GeoDataFrame()\n",
    "                    for index4, r4 in buffer_rivers.loc[buffer_rivers['NOID']==r3['NDOID']].iterrows():\n",
    "                        # If upstream river (r3) is flowing into downstream river (r4)                    \n",
    "                        if r3['NDOID'] == r4['NOID']:\n",
    "                            \n",
    "                            # Set the downstream river (r4)'s outside flow to the inflowing river (r3)'s flow\n",
    "                            buffer_rivers.at[index4, 'o_outside_dis'] = r4['o_outside_dis']  + r1['DIS_AV_CMS']\n",
    "\n",
    "                            print('o_outside_dis: ' + str(buffer_rivers.at[index4, 'o_outside_dis']))\n",
    "                                                        \n",
    "                            # Add r4 to become the next round's upstream river\n",
    "                            new_inters = new_inters.append(buffer_rivers.iloc[index4])\n",
    "                            \n",
    "                            # Check if r4 is already crossing the park boundary (leaving the park)\n",
    "                            if r4['inpark_par'] == 0:\n",
    "                                out_flow = 1\n",
    "                                \n",
    "                            else:\n",
    "                                buffer_rivers.at[index4, 'o_through_par'] = 1\n",
    "                                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate park contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index1, r1 in buffer_rivers.iterrows():\n",
    "    if (r1['o_outside_dis'] != 0) and r1['inpark_par'] == 1:\n",
    "        buffer_rivers.at[index1, 'o_park_dis'] = r1['DIS_AV_CMS'] - r1['o_outside_dis']\n",
    "        buffer_rivers.at[index1, 'o_park_fra'] = buffer_rivers.at[index1, 'o_park_dis']/r1['DIS_AV_CMS']\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine with rivers starting inside park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all rivers intersecting with park border\n",
    "# for index1, r1 in inters.iterrows():\n",
    "#     buffer_rivers['i_start_dis']=0.0 \n",
    "    \n",
    "#     # All rivers starting\n",
    "#     if r1['NUOID'] is None:\n",
    "#         buffer_rivers['park_dis']=0.0\n",
    "            \n",
    "new_inters = inters\n",
    "print('No of inters:' + str(inters.shape[0]))\n",
    "runs = 500\n",
    "run = 0\n",
    "while run < runs:\n",
    "    run += 1\n",
    "    print(round(100*run/runs))\n",
    "    \n",
    "    new_new_inters = new_inters\n",
    "    new_inters = gpd.GeoDataFrame()\n",
    "    \n",
    "    for index1, r1 in new_new_inters.iterrows():\n",
    "        \n",
    "        \n",
    "        # RIVERS STARTING IN PARK\n",
    "\n",
    "        # If river originates in park, and not flowing from the outside in.\n",
    "        if run == 1 and r1['o_inflow_par'] == 0:\n",
    "            # Set its own i_start_dis to its dis\n",
    "            buffer_rivers.loc[buffer_rivers['NOID']==r1['NOID'],'i_start_dis'] = r1['DIS_AV_CMS'] + r1['i_start_dis']\n",
    "\n",
    "\n",
    "        # If the river is downstream from another\n",
    "        else:\n",
    "            # Subset all rivers upstream from r1\n",
    "            upstream_ids1 = map(int, r1['NUOID'].split('_'))\n",
    "            upstream1 = buffer_rivers.loc[buffer_rivers['NOID'].isin(upstream_ids1)].reset_index()\n",
    "\n",
    "\n",
    "            # r1's i_start_dis will be equal to the sum of all the other's i_start_dis\n",
    "            buffer_rivers.at[index1, 'i_start_dis'] = upstream1['i_start_dis'].sum()\n",
    "            \n",
    "            if (r1['o_through_par'] == 0) and (r2['intersect_par'] == 0):\n",
    "                buffer_rivers.at[index1, 'o_park_dis'] = upstream1['o_park_dis'].sum()\n",
    "                buffer_rivers.at[index1, 'o_park_fra'] = upstream1['o_park_fra'].sum()\n",
    "                          \n",
    "\n",
    "            # POPULATE ALL RIVERS DOWNSTREAM\n",
    "\n",
    "        for index2, r2 in buffer_rivers.loc[buffer_rivers['NOID']==r1['NDOID']].iterrows():\n",
    "            \n",
    "            if (r1['NDOID'] == r2['NOID']):\n",
    "                new_inters = new_inters.append(buffer_rivers.iloc[index2])\n",
    "            \n",
    "\n",
    "                \n",
    "            # If the downstream river is actually also an inter and intersecting park\n",
    "#             if (r2['intersect_par'] == 1):\n",
    "#                 buffer_rivers.at[index2, 'o_park_dis'] = r2['DIS_AV_CMS']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_rivers['i_park_fra'] = buffer_rivers['i_start_dis']/buffer_rivers['DIS_AV_CMS']\n",
    "\n",
    "buffer_rivers['park_dis'] = buffer_rivers['o_park_dis'] + buffer_rivers['i_start_dis']\n",
    "\n",
    "buffer_rivers['park_fra'] = buffer_rivers['park_dis']/buffer_rivers['DIS_AV_CMS']\n",
    "\n",
    "\n",
    "# buffer_rivers['park_fra'] = (buffer_rivers['i_start_dis']/buffer_rivers['DIS_AV_CMS'])+ buffer_rivers['o_park_dis']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index1, r1 in buffer_rivers.iterrows():\n",
    "#     if buffer_rivers.at[index1, 'inpark_par'] == 1 and buffer_rivers.at[index1, 'o_through_par'] != 1 and buffer_rivers.at[index1, 'o_inflow_par'] == 0:\n",
    "#         buffer_rivers.at[index1, 'o_park_fra'] = 1\n",
    "#     if buffer_rivers.at[index1, 'o_park_dis'] < 0:\n",
    "#         buffer_rivers.at[index1, 'o_park_fra'] = 0\n",
    "#         buffer_rivers.at[index1, 'park_fra'] = 0  \n",
    "\n",
    "# relevant_rivers = buffer_rivers.loc[buffer_rivers['calc_p'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_rivers = buffer_rivers.loc[buffer_rivers['park_fra'] > 0]\n",
    "m = folium.Map([park.centroid.y, park.centroid.x],\n",
    "                  zoom_start=10,\n",
    "                  tiles='Stamen Terrain')\n",
    "\n",
    "def create_cols(dis):\n",
    "    if dis < 0.1:\n",
    "        col = '#3e5946'\n",
    "    else:\n",
    "        col = '#34278f'\n",
    "    return col\n",
    "\n",
    "relevant_rivers['col'] = pd.cut(relevant_rivers['park_fra'], bins=5, labels=['white', '#73a4af', '#4f84a2', '#253c5e', '#182749'])\n",
    "\n",
    "\n",
    "gj = folium.GeoJson(\n",
    "    relevant_rivers,\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': feature['properties']['col'],\n",
    "        'color' : feature['properties']['col'],\n",
    "        'weight' : 3,\n",
    "        'fillOpacity' : 0.5,\n",
    "        },\n",
    "    popup=folium.GeoJsonPopup(fields=[ 'DIS_AV_CMS',\n",
    "        'NOID', 'NDOID', 'NUOID', 'o_inflow_par', 'o_through_par', 'inpark_par', 'o_outside_dis',\n",
    "        'o_park_dis', 'o_park_fra', 'i_start_dis', 'i_park_fra', 'park_fra', 'park_dis'])\n",
    "    )\n",
    "\n",
    "park_plot = folium.GeoJson(\n",
    "    park,\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': 'red',\n",
    "        'color' : 'red',\n",
    "        'weight' : 3,\n",
    "        'fillOpacity' : 0.5,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "park_plot.add_to(m)\n",
    "gj.add_to(m)\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}